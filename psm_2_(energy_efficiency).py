# -*- coding: utf-8 -*-
"""PSM 2 (Energy Efficiency).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RS0R8Vt9K5FrjBiVwBLhB40UvlP7TOUh
"""

pip install ucimlrepo shap

"""# ** Data Imports and Preparation / Preprocessing **


"""

#General
import warnings

#Data
from ucimlrepo import fetch_ucirepo

#Data Processing
import pandas as pd
import numpy as np

#Visualation
import matplotlib.pyplot as plt
import seaborn as sns

#Scikitlearn
from sklearn.exceptions import ConvergenceWarning
from sklearn.model_selection import cross_val_score, KFold, train_test_split

# GENERAL
import warnings

# DATA
from ucimlrepo import fetch_ucirepo

# DATA Processing
import pandas as pd
import numpy as np

# Visualisation
import matplotlib.pyplot as plt
import seaborn as sns

# Scikitlearn
from sklearn.exceptions import ConvergenceWarning
from sklearn.model_selection import cross_val_score, KFold, train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import make_scorer, mean_squared_error, r2_score, mean_absolute_error
from sklearn.pipeline import Pipeline
from sklearn.metrics import make_scorer

# Linear Models
from sklearn.linear_model import LinearRegression

# MLP Regressor
from sklearn.neural_network import MLPRegressor

# Gaussian Naive Bayes
from sklearn.naive_bayes import GaussianNB

# Support Vector Regressor (SVR)
from sklearn.svm import SVR

# KNN
from sklearn.neighbors import KNeighborsRegressor

# Tree-Based Models
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# XGBoost
from xgboost import XGBRegressor, plot_importance

# SHAP
import shap

"""## ** Load a dataset from the UCI Machine**"""

def load_data_from_uci(id_code):

  # fetch dataset
  uci_data = fetch_ucirepo(id=id_code)

  # data (as pandas dataframes)
  input_features = uci_data.data.features
  target_feature = uci_data.data.targets
  metadata = uci_data.data.metadata
  variables_info = uci_data.data.variables

  return input_features, target_feature, metadata, variables_info

'''Go to UC Irvine Machine Learning reposity and find the Data Set you like
  https://archive.ics.uci.edu/dataset/242/energy+efficiency and then use Import
  in Python button and then Copy the Python Code into your Notebook
  to Load the Data
  '''

input_features, target_feature, metadata, variables_info =  load_data_from_uci(id_code = 242)

input_features.head()

input_features.info()

target_feature.head()

print(metadata)

print(variables_info)

input_features.describe().T

input_features.isna().sum()

target_feature.isna().sum()

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Plot distribution of all input features
input_features_names = input_features.columns

plt.figure(figsize=(15, 10))
colors = sns.color_palette("hsv", len(input_features_names))

for i, (feature, color) in enumerate(zip(input_features_names, colors), 1):
    plt.subplot(3, 3, i)
    if feature in ['Orientation', 'Glazing Area Distribution']:
        sns.histplot(input_features[feature], kde=False, color=color, bins=30)
    else:
        sns.histplot(input_features[feature], kde=True, color=color, bins=30)
    plt.title(f'Distribution of {feature}')
    plt.xlabel('')
    plt.ylabel('')

plt.tight_layout()
plt.show()

"""# **Linear Regressions**



---

## **Linear Regression**
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Generate synthetic data
np.random.seed(42)
X = np.linspace(0, 10, 100).reshape(-1, 1)
y = 3 * X.squeeze() + np.random.randn(100) * 2

# Define models
regression_models = {
    'Linear Regression': LinearRegression()
}

# Fit each model and plot the results
plt.figure(figsize=(15, 10))

for i, (name, model) in enumerate(regression_models.items(), 1):
    model.fit(X, y)
    y_pred = model.predict(X)

    plt.subplot(1, 1, i)
    plt.scatter(X, y, color='blue', label='Data')
    plt.plot(X, y_pred, color='red', label='Fit')
    plt.title(name)
    plt.xlabel('X')
    plt.ylabel('y')
    plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.decomposition import PCA

# Generate synthetic multivariate data
np.random.seed(42)
X, y = make_regression(n_samples=100, n_features=10, noise=0.1)

# Add some nonlinearity
y += np.sin(X[:, 0]) * 10

# Add some outliers
n_outliers = 5
outliers_index = np.random.choice(np.arange(100), n_outliers, replace=False)
y[outliers_index] += 20 * np.random.randn(n_outliers)

# Define models
regression_models = {
    'Linear Regression': LinearRegression()
}

# Fit the model, apply PCA, and plot the results
plt.figure(figsize=(15, 10))

for i, (name, model) in enumerate(regression_models.items(), 1):
    model.fit(X, y)
    y_pred = model.predict(X)

    # Calculate performance metrics
    mse = mean_squared_error(y, y_pred)
    r2 = r2_score(y, y_pred)
    mae = mean_absolute_error(y, y_pred)

    # Apply PCA to reduce to one dimension for visualization
    pca = PCA(n_components=1)
    X_pca = pca.fit_transform(X)

    plt.subplot(1, 1, i)
    plt.scatter(X_pca, y, color='blue', label='Data')
    plt.scatter(X_pca, y_pred, color='red', label='Prediction', alpha=0.5)
    plt.title(name)
    plt.xlabel('Principal Component 1')
    plt.ylabel('y')
    plt.legend()

    # Add performance metrics to the plot
    plt.text(0.05, 0.95, f'MSE: {mse:.2f}\nR²: {r2:.2f}\nMAE: {mae:.2f}',
             transform=plt.gca().transAxes, fontsize=10,
             verticalalignment='top', horizontalalignment='left',
             bbox=dict(boxstyle='round,pad=0.5', facecolor='black', edgecolor='none', alpha=0.8), color='white')

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Generate synthetic data with nonlinearity and outliers
np.random.seed(42)
X = np.linspace(0, 10, 100).reshape(-1, 1)
y = 3 * X.squeeze() + np.sin(X).squeeze() * 10 + np.random.randn(100) * 2

# Add outliers
X_outliers = np.array([1, 3, 5, 7, 9]).reshape(-1, 1)
y_outliers = np.array([30, -10, 25, -15, 40])
X = np.vstack([X, X_outliers])
y = np.concatenate([y, y_outliers])

# Define model
regression_model = {
    'Linear Regression': LinearRegression()
}

# Fit the model and plot the results
plt.figure(figsize=(10, 8))

for i, (name, model) in enumerate(regression_model.items(), 1):
    model.fit(X, y)
    y_pred = model.predict(X)

    plt.scatter(X, y, color='blue', label='Data')
    plt.plot(X, y_pred, color='red', label='Fit')
    plt.title(name)
    plt.xlabel('X')
    plt.ylabel('y')
    plt.legend()

plt.tight_layout()
plt.show()

"""### **Evaluation Metric**"""

import numpy as np
import pandas as pd
import warnings
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold, cross_val_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Ignore convergence warnings
warnings.filterwarnings(action='ignore', category=ConvergenceWarning, module='sklearn.linear_model._least_angle')

# Identify categorical features: 'Orientation', 'Glazing Area Distribution'
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(), categorical_features),
                  ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])]
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)

    # Cross-validation for MSE, MAE, and R²
    mse_scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring='r2', cv=kf, error_score='raise')

    return np.mean(-mse_scores), np.mean(-mae_scores), np.mean(r2_scores)

# Define model for regression tasks
regression_model = {
    'Linear Regression': LinearRegression()
}

# Initialize the results dictionary to store heating and cooling load results separately
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Evaluate the regression model and store results
for name, model in regression_model.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, mae_heating, r2_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, mae_cooling, r2_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
        results['Cooling Load R²'].append(r2_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy viewing
results_df = pd.DataFrame(results)

# Display the results in table format
print("Results for Heating and Cooling Loads:")
print(results_df)

"""### **Results**"""

print(results_df[['Model', 'Heating Load MSE', 'Heating Load R²', 'Heating Load MAE']])

print(results_df[['Model', 'Heating Load MSE', 'Heating Load R²', 'Heating Load MAE']])

"""#### **Scatter Plot**"""

import numpy as np
import pandas as pd
import warnings
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold, cross_val_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Ignore convergence warnings
warnings.filterwarnings(action='ignore', category=ConvergenceWarning, module='sklearn.linear_model._least_angle')

# Identify categorical features: 'Orientation', 'Glazing Area Distribution'
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(), categorical_features),
                  ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])],
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)

    # Cross-validation for MSE, MAE, and R²
    mse_scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring='r2', cv=kf, error_score='raise')

    return np.mean(-mse_scores), np.mean(-mae_scores), np.mean(r2_scores)

# Define model for regression tasks
regression_model = {
    'Linear Regression': LinearRegression()
}

# Initialize the results dictionary to store heating and cooling load results separately
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Evaluate the regression model and store results
for name, model in regression_model.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, mae_heating, r2_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, mae_cooling, r2_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
        results['Cooling Load R²'].append(r2_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy viewing
results_df = pd.DataFrame(results)

# Display the results in table format
print("Results for Heating and Cooling Loads:")
print(results_df)

# Train the linear regression model for heating and cooling load
lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())])

# Train the model on heating and cooling load
lr_pipeline.fit(input_features, y_heating)
y_heating_pred = lr_pipeline.predict(input_features)

lr_pipeline.fit(input_features, y_cooling)
y_cooling_pred = lr_pipeline.predict(input_features)

# Plot predicted vs actual scatter plots
fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=100)

# Heating Load Plot
axes[0].scatter(y_heating, y_heating_pred, color='red', label='Predicted', alpha=0.6)
axes[0].plot([y_heating.min(), y_heating.max()], [y_heating.min(), y_heating.max()], 'k--', label='Ideal Fit')
axes[0].set_xlabel("Actual Heating Load")
axes[0].set_ylabel("Predicted Heating Load")
axes[0].set_title("Heating Load Prediction (Linear Regression)")
axes[0].legend()

# Cooling Load Plot
axes[1].scatter(y_cooling, y_cooling_pred, color='blue', label='Predicted', alpha=0.6)
axes[1].plot([y_cooling.min(), y_cooling.max()], [y_cooling.min(), y_cooling.max()], 'k--', label='Ideal Fit')
axes[1].set_xlabel("Actual Cooling Load")
axes[1].set_ylabel("Predicted Cooling Load")
axes[1].set_title("Cooling Load Prediction (Linear Regression)")
axes[1].legend()

plt.tight_layout()
plt.show()

"""# **Support Vector Machines**


---

## **Evaluation Metric**
"""

import numpy as np
import pandas as pd
import warnings
from sklearn.svm import SVR
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import make_scorer

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Ignore convergence warnings for LARS model
warnings.filterwarnings(action='ignore', category=ConvergenceWarning, module='sklearn.linear_model._least_angle')

# Identify categorical features: 'Orientation', 'Glazing Area Distribution'
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(), categorical_features),
                  ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])]
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Define the SVR model for regression tasks
regression_models = {
    'SVR': SVR()
}

# Initialize the results dictionary to store heating and cooling load results separately
results = {
    'Model': [],
    'Heating Load MSE': [],
    'Heating Load R²': [],
    'Heating Load MAE': [],
    'Cooling Load MSE': [],
    'Cooling Load R²': [],
    'Cooling Load MAE': []
}

# Evaluate the SVR model and store results
for name, model in regression_models.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load R²'].append(r2_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy plotting
results_df = pd.DataFrame(results)

# Print the results table
print("Results for Heating and Cooling Loads :")
print(results_df)

"""### **Results**"""

print(results_df[['Model', 'Heating Load MSE', 'Heating Load R²', 'Heating Load MAE']])

print(results_df[['Model', 'Cooling Load MSE', 'Cooling Load R²', 'Cooling Load MAE']])

"""#### **Scatter Plot**"""

import numpy as np
import pandas as pd
import warnings
from sklearn.svm import SVR
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import make_scorer
import matplotlib.pyplot as plt

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Ignore convergence warnings for LARS model
warnings.filterwarnings(action='ignore', category=ConvergenceWarning, module='sklearn.linear_model._least_angle')

# Identify categorical features: 'Orientation', 'Glazing Area Distribution'
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(), categorical_features),
                  ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])],
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Define the SVR model for regression tasks
regression_models = {
    'SVR': SVR()
}

# Initialize the results dictionary to store heating and cooling load results separately
results = {
    'Model': [],
    'Heating Load MSE': [],
    'Heating Load R²': [],
    'Heating Load MAE': [],
    'Cooling Load MSE': [],
    'Cooling Load R²': [],
    'Cooling Load MAE': []
}

# Evaluate the SVR model and store results
for name, model in regression_models.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load R²'].append(r2_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy plotting
results_df = pd.DataFrame(results)

# Fit the model pipeline on the full dataset to generate predictions for plotting
svr_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', SVR())])

# Train the model on heating and cooling load
svr_pipeline.fit(input_features, y_heating)
y_heating_pred = svr_pipeline.predict(input_features)

svr_pipeline.fit(input_features, y_cooling)
y_cooling_pred = svr_pipeline.predict(input_features)

# Plot predicted vs actual scatter plots
fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=100)

# Heating Load Plot
axes[0].scatter(y_heating, y_heating_pred, color='red', label='Predicted', alpha=0.6)
axes[0].plot([y_heating.min(), y_heating.max()], [y_heating.min(), y_heating.max()], 'k--', label='Ideal Fit')
axes[0].set_xlabel("Actual Heating Load")
axes[0].set_ylabel("Predicted Heating Load")
axes[0].set_title("Heating Load Prediction (SVR)")
axes[0].legend()

# Cooling Load Plot
axes[1].scatter(y_cooling, y_cooling_pred, color='blue', label='Predicted', alpha=0.6)
axes[1].plot([y_cooling.min(), y_cooling.max()], [y_cooling.min(), y_cooling.max()], 'k--', label='Ideal Fit')
axes[1].set_xlabel("Actual Cooling Load")
axes[1].set_ylabel("Predicted Cooling Load")
axes[1].set_title("Cooling Load Prediction (SVR)")
axes[1].legend()

plt.tight_layout()
plt.show()

"""# **Nearest Neighbour**

---

## **Evaluation Metric**
"""

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Ignore convergence warnings
warnings.filterwarnings(action='ignore', category=ConvergenceWarning, module='sklearn.linear_model._least_angle')

# Identify categorical features
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features),
        ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])
    ])

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Define K-Nearest Neighbors Regressor model
regression_models = {
    'KNeighbors Regressor': KNeighborsRegressor()
}

# Initialize the results dictionary to store heating and cooling load results separately
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Evaluate all regression models and store results
for name, model in regression_models.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
        results['Cooling Load R²'].append(r2_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy plotting
results_df = pd.DataFrame(results)

# Print the results
print("Results for Heating and Cooling Loads:")
print(results_df)

"""### **Results**"""

print(results_df[['Model', 'Heating Load MSE', 'Heating Load MAE', 'Heating Load R²']])

print(results_df[['Model', 'Cooling Load MSE', 'Cooling Load MAE', 'Cooling Load R²']])

"""#### **Scatter Plot**"""

import numpy as np
import pandas as pd
import warnings
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold, cross_val_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from sklearn.metrics import make_scorer
from sklearn.neighbors import KNeighborsRegressor

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Ignore convergence warnings
warnings.filterwarnings(action='ignore', category=ConvergenceWarning, module='sklearn.linear_model._least_angle')

# Identify categorical features
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features),
        ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])
    ])

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Define K-Nearest Neighbors Regressor model
regression_models = {
    'KNeighbors Regressor': KNeighborsRegressor()
}

# Initialize the results dictionary to store heating and cooling load results separately
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Evaluate all regression models and store results
for name, model in regression_models.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
        results['Cooling Load R²'].append(r2_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy viewing
results_df = pd.DataFrame(results)

# Print the results
print("Results for Heating and Cooling Loads:")
print(results_df)

# Fit the model to the data
model_pipeline.fit(input_features, y_heating)
y_heating_pred = model_pipeline.predict(input_features)
model_pipeline.fit(input_features, y_cooling)
y_cooling_pred = model_pipeline.predict(input_features)

# Create scatter plot for Heating Load Predictions
plt.figure(figsize=(12, 6))

# Heating Load - Actual vs Predicted
plt.subplot(1, 2, 1)
plt.scatter(y_heating, y_heating_pred, color='red', alpha=0.6, label='Predicted vs Actual')
plt.plot([min(y_heating), max(y_heating)], [min(y_heating), max(y_heating)], 'k--', label='Ideal Fit')
plt.xlabel("Actual Heating Load")
plt.ylabel("Predicted Heating Load")
plt.title("Heating Load Prediction (KNN)")
plt.legend()

# Cooling Load - Actual vs Predicted
plt.subplot(1, 2, 2)
plt.scatter(y_cooling, y_cooling_pred, color='blue', alpha=0.6, label='Predicted vs Actual')
plt.plot([min(y_cooling), max(y_cooling)], [min(y_cooling), max(y_cooling)], 'k--', label='Ideal Fit')
plt.xlabel("Actual Cooling Load")
plt.ylabel("Predicted Cooling Load")
plt.title("Cooling Load Prediction (KNN)")
plt.legend()

# Display the plot
plt.tight_layout()
plt.show()

"""# **Decision Tree**

---

## **Evaluation Metric**
"""

import numpy as np
import pandas as pd
import warnings
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

# Rename columns for better readability
column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}
input_features.rename(columns=column_mapping, inplace=True)

# Ignore warnings
warnings.filterwarnings(action='ignore', category=UserWarning, module='sklearn')

# Identify categorical features
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features),
        ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])
    ]
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Initialize the results dictionary to store heating and cooling load results
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Define and evaluate the Gradient Boosting Regressor
model_name = 'Gradient Boosting Regressor'
model = GradientBoostingRegressor()

try:
    print(f"Evaluating {model_name}...")  # Debugging message to track progress
    # Create a pipeline that includes preprocessing and the model
    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                      ('regressor', model)])

    # Evaluate for heating and cooling load
    mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
    mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

    # Append results for heating and cooling load
    results['Model'].append(model_name)
    results['Heating Load MSE'].append(mse_heating)
    results['Heating Load MAE'].append(mae_heating)
    results['Heating Load R²'].append(r2_heating)
    results['Cooling Load MSE'].append(mse_cooling)
    results['Cooling Load MAE'].append(mae_cooling)
    results['Cooling Load R²'].append(r2_cooling)
except Exception as e:
    print(f"Model {model_name} failed with error: {e}")  # Print any error encountered

# Convert results to DataFrame for better visualization
results_df = pd.DataFrame(results)

# Heating and cooling load results
heating_df = results_df[['Model', 'Heating Load MSE', 'Heating Load MAE', 'Heating Load R²']]
cooling_df = results_df[['Model', 'Cooling Load MSE', 'Cooling Load MAE', 'Cooling Load R²']]

# Print the results
print("Results for Gradient Boosting Regressor (Heating and Cooling Loads):")
print("\nHeating Load:")
print(heating_df)
print("\nCooling Load:")
print(cooling_df)

"""### **Results**"""

print(results_df[['Model', 'Heating Load MSE', 'Heating Load MAE', 'Heating Load R²']])

print(results_df[['Model', 'Cooling Load MSE', 'Cooling Load MAE', 'Cooling Load R²']])

"""#### **Scatter Plot**"""

import numpy as np
import pandas as pd
import warnings
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
import matplotlib.pyplot as plt

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

# Rename columns for better readability
column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}
input_features.rename(columns=column_mapping, inplace=True)

# Ignore warnings
warnings.filterwarnings(action='ignore', category=UserWarning, module='sklearn')

# Identify categorical features
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features),
        ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])
    ]
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Initialize the results dictionary to store heating and cooling load results
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Define and evaluate the Gradient Boosting Regressor
model_name = 'Gradient Boosting Regressor'
model = GradientBoostingRegressor()

try:
    print(f"Evaluating {model_name}...")  # Debugging message to track progress
    # Create a pipeline that includes preprocessing and the model
    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                      ('regressor', model)])

    # Evaluate for heating and cooling load
    mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
    mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

    # Append results for heating and cooling load
    results['Model'].append(model_name)
    results['Heating Load MSE'].append(mse_heating)
    results['Heating Load MAE'].append(mae_heating)
    results['Heating Load R²'].append(r2_heating)
    results['Cooling Load MSE'].append(mse_cooling)
    results['Cooling Load MAE'].append(mae_cooling)
    results['Cooling Load R²'].append(r2_cooling)
except Exception as e:
    print(f"Model {model_name} failed with error: {e}")  # Print any error encountered

# Convert results to DataFrame for better visualization
results_df = pd.DataFrame(results)

# Heating and cooling load results
heating_df = results_df[['Model', 'Heating Load MSE', 'Heating Load MAE', 'Heating Load R²']]
cooling_df = results_df[['Model', 'Cooling Load MSE', 'Cooling Load MAE', 'Cooling Load R²']]

# Print the results
print("Results for Gradient Boosting Regressor (Heating and Cooling Loads):")
print("\nHeating Load:")
print(heating_df)
print("\nCooling Load:")
print(cooling_df)

# Fit the model to the data
model_pipeline.fit(input_features, y_heating)
y_heating_pred = model_pipeline.predict(input_features)
model_pipeline.fit(input_features, y_cooling)
y_cooling_pred = model_pipeline.predict(input_features)

# Create scatter plot for Heating Load Predictions
plt.figure(figsize=(12, 6))

# Heating Load - Actual vs Predicted
plt.subplot(1, 2, 1)
plt.scatter(y_heating, y_heating_pred, color='red', alpha=0.6, label='Predicted vs Actual')
plt.plot([min(y_heating), max(y_heating)], [min(y_heating), max(y_heating)], 'k--', label='Ideal Fit')
plt.xlabel("Actual Heating Load")
plt.ylabel("Predicted Heating Load")
plt.title("Heating Load Prediction (Gradient Boosting Regressor)")
plt.legend()

# Cooling Load - Actual vs Predicted
plt.subplot(1, 2, 2)
plt.scatter(y_cooling, y_cooling_pred, color='blue', alpha=0.6, label='Predicted vs Actual')
plt.plot([min(y_cooling), max(y_cooling)], [min(y_cooling), max(y_cooling)], 'k--', label='Ideal Fit')
plt.xlabel("Actual Cooling Load")
plt.ylabel("Predicted Cooling Load")
plt.title("Cooling Load Prediction (Gradient Boosting Regressor)")
plt.legend()

# Display the plot
plt.tight_layout()
plt.show()

"""# **Neural Network**


---

## **Evaluation Metric**
"""

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}

input_features.rename(columns=column_mapping, inplace=True)

# Ignore convergence warnings for LARS model
warnings.filterwarnings(action='ignore', category=ConvergenceWarning, module='sklearn.linear_model._least_angle')

# Identify categorical features: 'Orientation', 'Glazing Area Distribution'
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(), categorical_features),
                  ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])]
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Define ensemble models for regression tasks
regression_models = {
    'MLP Regressor': MLPRegressor()
}

# Initialize the results dictionary to store heating and cooling load results separately
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Evaluate all regression models and store results
for name, model in regression_models.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
        results['Cooling Load R²'].append(r2_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy plotting
results_df = pd.DataFrame(results)

# Print the results
print(results_df)

"""### **Results**"""

print(results_df[['Model', 'Heating Load MSE', 'Heating Load MAE', 'Heating Load R²']])

print(results_df[['Model', 'Cooling Load MSE', 'Cooling Load MAE', 'Cooling Load R²']])

"""#### **Scatter Plot**"""

import numpy as np
import pandas as pd
import warnings
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

# Rename columns for better readability
column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}
input_features.rename(columns=column_mapping, inplace=True)

# Ignore warnings
warnings.filterwarnings(action='ignore', category=UserWarning, module='sklearn')

# Identify categorical features
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with OneHotEncoder for categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features),
        ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])
    ]
)

# Function to evaluate models with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf, error_score='raise')
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf, error_score='raise')
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf, error_score='raise')

    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Define and evaluate the MLP Regressor model
regression_models = {
    'MLP Regressor': MLPRegressor()
}

# Initialize the results dictionary to store heating and cooling load results
results = {'Model': [],
           'Heating Load MSE': [], 'Heating Load MAE': [], 'Heating Load R²': [],
           'Cooling Load MSE': [], 'Cooling Load MAE': [], 'Cooling Load R²': []}

# Evaluate all regression models and store results
for name, model in regression_models.items():
    try:
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                          ('regressor', model)])

        mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Append results for heating and cooling load
        results['Model'].append(name)
        results['Heating Load MSE'].append(mse_heating)
        results['Heating Load MAE'].append(mae_heating)
        results['Heating Load R²'].append(r2_heating)
        results['Cooling Load MSE'].append(mse_cooling)
        results['Cooling Load MAE'].append(mae_cooling)
        results['Cooling Load R²'].append(r2_cooling)
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for easy plotting
results_df = pd.DataFrame(results)

# Print the results
print(results_df)

# Fit the model to the data
model_pipeline.fit(input_features, y_heating)
y_heating_pred = model_pipeline.predict(input_features)
model_pipeline.fit(input_features, y_cooling)
y_cooling_pred = model_pipeline.predict(input_features)

# Create scatter plot for Heating Load Predictions
plt.figure(figsize=(12, 6))

# Heating Load - Actual vs Predicted
plt.subplot(1, 2, 1)
plt.scatter(y_heating, y_heating_pred, color='red', alpha=0.6, label='Predicted vs Actual')
plt.plot([min(y_heating), max(y_heating)], [min(y_heating), max(y_heating)], 'k--', label='Ideal Fit')
plt.xlabel("Actual Heating Load")
plt.ylabel("Predicted Heating Load")
plt.title("Heating Load Prediction (MLP Regressor)")
plt.legend()

# Cooling Load - Actual vs Predicted
plt.subplot(1, 2, 2)
plt.scatter(y_cooling, y_cooling_pred, color='blue', alpha=0.6, label='Predicted vs Actual')
plt.plot([min(y_cooling), max(y_cooling)], [min(y_cooling), max(y_cooling)], 'k--', label='Ideal Fit')
plt.xlabel("Actual Cooling Load")
plt.ylabel("Predicted Cooling Load")
plt.title("Cooling Load Prediction (MLP Regressor)")
plt.legend()

# Display the plot
plt.tight_layout()
plt.show()

"""# **Model Selection**

---


"""

# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import KFold, cross_val_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor

# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

# Rename columns for better readability
column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}
input_features.rename(columns=column_mapping, inplace=True)

# Identify categorical features
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer with preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features),
        ('num', StandardScaler(), [col for col in input_features.columns if col not in categorical_features])
    ]
)

# Function to evaluate the model with cross-validation
def evaluate_model_cv(model, X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    mse_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_squared_error), cv=kf)
    mae_scores = cross_val_score(model, X, y, scoring=make_scorer(mean_absolute_error), cv=kf)
    r2_scores = cross_val_score(model, X, y, scoring=make_scorer(r2_score), cv=kf)
    return np.mean(mse_scores), np.mean(r2_scores), np.mean(mae_scores)

# Define models to be evaluated
regression_models = {
    'Linear Regression': LinearRegression(),
    'Support Vector Regressor (SVR)': SVR(),
    'K-Nearest Neighbors (KNN)': KNeighborsRegressor(),
    'Gradient Boosting Regressor': GradientBoostingRegressor(),
    'MLP Regressor': MLPRegressor(max_iter=500)
}

# Evaluate all regression models and store results
results = {}
for name, model in regression_models.items():
    try:
        print(f"Evaluating {name}...")  # Debugging message to track progress
        # Create a pipeline that includes preprocessing and the model
        model_pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', model)
        ])
        mse_heating, r2_heating, mae_heating = evaluate_model_cv(model_pipeline, input_features, y_heating)
        mse_cooling, r2_cooling, mae_cooling = evaluate_model_cv(model_pipeline, input_features, y_cooling)

        # Store results for heating and cooling load
        results[name] = {
            'Heating Load': {'MSE': np.round(mse_heating, 4),
                             'R2': np.round(r2_heating, 4),
                             'MAE': np.round(mae_heating, 4)},
            'Cooling Load': {'MSE': np.round(mse_cooling, 4),
                             'R2': np.round(r2_cooling, 4),
                             'MAE': np.round(mae_cooling, 4)}
        }
    except Exception as e:
        print(f"Model {name} failed with error: {e}")

# Convert results to DataFrame for better visualization
results_df = pd.DataFrame(results).T

# Print the results
print("Evaluation Results for Selected Models:")
print(results_df)

"""## **Results**"""

# Print specific metrics for Heating Load for each model
print(results_df['Heating Load'].apply(pd.Series)[['MSE', 'R2', 'MAE']])

print(results_df['Cooling Load'].apply(pd.Series)[['MSE', 'R2', 'MAE']])

"""### **Best Model**"""

# Find the best model for each metric
best_models = {}
for load_type in ['Heating Load', 'Cooling Load']:
    best_mse_model = results_df[load_type].apply(lambda x: x['MSE']).idxmin()
    best_r2_model = results_df[load_type].apply(lambda x: x['R2']).idxmax()
    best_mae_model = results_df[load_type].apply(lambda x: x['MAE']).idxmin()
    best_models[load_type] = {
        'Best MSE Model': best_mse_model,
        'Best R2 Model': best_r2_model,
        'Best MAE Model': best_mae_model
    }

# Print best models for each metric
for load_type, metrics in best_models.items():
    print(f"\n{load_type}:")
    for metric, model in metrics.items():
        print(f"  {metric}: {model}")

"""#### **Best Model Display**"""

# Plotting
fig, axes = plt.subplots(3, 2, figsize=(9, 12))  # Adjusted the layout to 3 rows

# Plot R2
results_df['Heating Load'].apply(lambda x: x['R2']).plot(kind='bar', ax=axes[0, 0], title='R2 - Heating Load', color='red')
results_df['Cooling Load'].apply(lambda x: x['R2']).plot(kind='bar', ax=axes[0, 1], title='R2 - Cooling Load')
axes[0, 0].set_ylabel('R2')
axes[0, 1].set_ylabel('R2')

# Plot MSE
results_df['Heating Load'].apply(lambda x: x['MSE']).plot(kind='bar', ax=axes[1, 0], title='MSE - Heating Load', color='red')
results_df['Cooling Load'].apply(lambda x: x['MSE']).plot(kind='bar', ax=axes[1, 1], title='MSE - Cooling Load')
axes[1, 0].set_ylabel('MSE')
axes[1, 1].set_ylabel('MSE')

# Plot MAE
results_df['Heating Load'].apply(lambda x: x['MAE']).plot(kind='bar', ax=axes[2, 0], title='MAE - Heating Load', color='red')
results_df['Cooling Load'].apply(lambda x: x['MAE']).plot(kind='bar', ax=axes[2, 1], title='MAE - Cooling Load')
axes[2, 0].set_ylabel('MAE')
axes[2, 1].set_ylabel('MAE')

# Adjust layout
plt.tight_layout()
plt.show()

"""# **Building Final Model**

---


"""

!pip install ucimlrepo

# Import necessary libraries
from ucimlrepo import fetch_ucirepo
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import pandas as pd


def load_data_from_uci(id_code):
    """
    Loads a dataset from the UCI Machine Learning Repository.

    Args:
        id_code (int): The ID code of the dataset to load.

    Returns:
        tuple: A tuple containing the input features, target feature, metadata, and variable information.
    """
    # fetch dataset
    uci_data = fetch_ucirepo(id=id_code)

    # data (as pandas dataframes)
    input_features = uci_data.data.features
    target_feature = uci_data.data.targets
    metadata = uci_data.data.metadata
    variables_info = uci_data.data.variables

    return input_features, target_feature, metadata, variables_info


# Load your data
input_features, target_feature, metadata, variables_info = load_data_from_uci(id_code=242)
y_heating = target_feature['Y1']
y_cooling = target_feature['Y2']

# Rename columns for better readability
column_mapping = {
    'X1': 'Relative Compactness',
    'X2': 'Surface Area',
    'X3': 'Wall Area',
    'X4': 'Roof Area',
    'X5': 'Overall Height',
    'X6': 'Orientation',
    'X7': 'Glazing Area',
    'X8': 'Glazing Area Distribution'
}
input_features.rename(columns=column_mapping, inplace=True)

# Identify categorical features
categorical_features = ['Orientation', 'Glazing Area Distribution']

# Define the column transformer
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', Pipeline(steps=[
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), categorical_features),
        ('num', Pipeline(steps=[
            ('scaler', StandardScaler())
        ]), [col for col in input_features.columns if col not in categorical_features])
    ])

# Split the data into training and testing sets
X_train, X_test, y_train_heating, y_test_heating, y_train_cooling, y_test_cooling = train_test_split(
    input_features,
    y_heating, y_cooling,
    test_size=0.2, random_state=42
)

# Create a pipeline for the Gradient Boosting model
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', GradientBoostingRegressor(random_state=42))
])

# Train and predict for Heating Load
model_pipeline.fit(X_train, y_train_heating)
y_pred_heating = model_pipeline.predict(X_test)

# Train and predict for Cooling Load
model_pipeline.fit(X_train, y_train_cooling)
y_pred_cooling = model_pipeline.predict(X_test)

# Calculate metrics for Heating Load
mse_heating = mean_squared_error(y_test_heating, y_pred_heating)
mae_heating = mean_absolute_error(y_test_heating, y_pred_heating)
r2_heating = r2_score(y_test_heating, y_pred_heating)

# Calculate metrics for Cooling Load
mse_cooling = mean_squared_error(y_test_cooling, y_pred_cooling)
mae_cooling = mean_absolute_error(y_test_cooling, y_pred_cooling)
r2_cooling = r2_score(y_test_cooling, y_pred_cooling)

# Print Results
print("Heating Load:")
print(f"MSE: {mse_heating:.4f}")
print(f"MAE: {mae_heating:.4f}")
print(f"R2: {r2_heating:.4f}")

print("\nCooling Load:")
print(f"MSE: {mse_cooling:.4f}")
print(f"MAE: {mae_cooling:.4f}")
print(f"R2: {r2_cooling:.4f}")

"""# **Applying the final model**

---


"""

# Import necessary libraries
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# Calculate performance metrics
mse_heating = mean_squared_error(y_test_heating, y_pred_heating)
r2_heating = r2_score(y_test_heating, y_pred_heating)
mae_heating = mean_absolute_error(y_test_heating, y_pred_heating)

mse_cooling = mean_squared_error(y_test_cooling, y_pred_cooling)
r2_cooling = r2_score(y_test_cooling, y_pred_cooling)
mae_cooling = mean_absolute_error(y_test_cooling, y_pred_cooling)

# Print performance metrics
print(f"Heating Load - MSE: {mse_heating:.4f}, R2: {r2_heating:.4f}, MAE: {mae_heating:.4f}")
print(f"Cooling Load - MSE: {mse_cooling:.4f}, R2: {r2_cooling:.4f}, MAE: {mae_cooling:.4f}")

# Visualize the actual vs predicted values
plt.figure(figsize=(14, 6))

# Heating Load
plt.subplot(1, 2, 1)
plt.scatter(y_test_heating, y_pred_heating, color='red', alpha=0.5)
plt.plot([y_test_heating.min(), y_test_heating.max()],
         [y_test_heating.min(), y_test_heating.max()],
         'k--', lw=2)
plt.xlabel('Actual Heating Load')
plt.ylabel('Predicted Heating Load')
plt.title('Actual vs Predicted Heating Load')

# Cooling Load
plt.subplot(1, 2, 2)
plt.scatter(y_test_cooling, y_pred_cooling, color='blue', alpha=0.5)
plt.plot([y_test_cooling.min(), y_test_cooling.max()],
         [y_test_cooling.min(), y_test_cooling.max()],
         'k--', lw=2)
plt.xlabel('Actual Cooling Load')
plt.ylabel('Predicted Cooling Load')
plt.title('Actual vs Predicted Cooling Load')

plt.tight_layout()
plt.show()

"""# **Explaining the final model**

---


"""

# Extract the Gradient Boosting Regressor model from the pipeline
gbr_model_heating = model_pipeline.named_steps['regressor']
gbr_model_cooling = model_pipeline.named_steps['regressor']

# Get feature names
preprocessed_feature_names = model_pipeline.named_steps['preprocessor'].get_feature_names_out()

# Get feature importances
importances_heating = gbr_model_heating.feature_importances_
importances_cooling = gbr_model_cooling.feature_importances_

# Convert the feature importance to a DataFrame and map the feature names
importance_df_heating = pd.DataFrame({
    'Feature': preprocessed_feature_names,
    'Importance': importances_heating
}).sort_values(by='Importance', ascending=False)

importance_df_cooling = pd.DataFrame({
    'Feature': preprocessed_feature_names,
    'Importance': importances_cooling
}).sort_values(by='Importance', ascending=False)

# Print the feature importance for Heating Load
print("Feature Importance for Heating Load:")
print(importance_df_heating)

# Print the feature importance for Cooling Load
print("\nFeature Importance for Cooling Load:")
print(importance_df_cooling)

# Plot feature importance for Heating Load
plt.figure(figsize=(10, 5))
importance_df_heating.sort_values(by='Importance').plot(kind='barh', x='Feature', y='Importance', legend=False, color='red')
plt.title('Feature Importance (Heating Load)')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

# Plot feature importance for Cooling Load
plt.figure(figsize=(10, 5))
importance_df_cooling.sort_values(by='Importance').plot(kind='barh', x='Feature', y='Importance', legend=False, color='blue')
plt.title('Feature Importance (Cooling Load)')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

"""SHAP

---






"""

from sklearn.ensemble import GradientBoostingRegressor

# Update the model in the pipeline to Gradient Boosting Regressor
model_pipeline.named_steps['regressor'] = GradientBoostingRegressor()

# Train the model for Heating Load and use SHAP
model_pipeline.fit(X_train, y_train_heating)
explainer_heating = shap.Explainer(model_pipeline.named_steps['regressor'],
                                   model_pipeline.named_steps['preprocessor'].transform(X_train))
shap_values_heating = explainer_heating(model_pipeline.named_steps['preprocessor'].transform(X_test))

# Train the model for Cooling Load and use SHAP
model_pipeline.fit(X_train, y_train_cooling)
explainer_cooling = shap.Explainer(model_pipeline.named_steps['regressor'],
                                   model_pipeline.named_steps['preprocessor'].transform(X_train))
shap_values_cooling = explainer_cooling(model_pipeline.named_steps['preprocessor'].transform(X_test))

# Get feature names after preprocessing
preprocessed_feature_names = model_pipeline.named_steps['preprocessor'].get_feature_names_out()

# Summary plot for Heating Load
shap.summary_plot(shap_values_heating, feature_names=preprocessed_feature_names, show=False)
plt.title('SHAP Summary Plot (Heating Load)')
plt.show()

# Summary plot for Cooling Load
shap.summary_plot(shap_values_cooling, feature_names=preprocessed_feature_names, show=False)
plt.title('SHAP Summary Plot (Cooling Load)')
plt.show()